
experiment:
  experiment_name: "eo-vae-sr-batch-karras-decay"
  exp_dir: "results/exps/eo-vae/sr"

wandb:
  project: eo-vae-sr
  entity: nleh
  mode: online

trainer:
  _target_: lightning.Trainer
  max_epochs: 750
  accelerator: "gpu"
  limit_val_batches: 10
  # limit_train_batches: 2000 # choose 1000 iterable dataset batches to have control over params
  # strategy: ddp_find_unused_parameters_true
  devices: [6]
  log_every_n_steps: 20
  gradient_clip_val: 0.5


lightning_module:
  _target_: eo_vae.models.super_res.DiffusionSuperRes
  base_lr: 1e-4
  final_lr: 1e-5
  warmup_epochs: 10
  decay_end_epoch: ${trainer.max_epochs}
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
  denoiser:
    _target_: azula.denoise.KarrasDenoiser
    # _target_: eo_vae.models.my_flow_model.MySimpleDenoiser
    backbone:
      _target_: azula.nn.unet.UNet
      in_channels: 32
      out_channels: 32
      cond_channels: 32
      hid_channels: [256, 128, 64]
      hid_blocks: [3, 3, 3]
      spatial: 2 #
    schedule:
      _target_: azula.noise.DecaySchedule
  sampler:
    _target_: azula.sample.DDIMSampler
    _partial_: true
    steps: 50

autoencoder:
  _target_: eo_vae.models.new_autoencoder.EOFluxVAE
  freeze_body: True
  loss_fn:
    _target_: torch.nn.Identity
  encoder:
    _target_: eo_vae.models.Encoder
    z_channels: 32
    resolution: 256
    in_channels: 3
    ch: 128
    ch_mult: [ 1,2,4,4 ]  # num_down = len(ch_mult)-1
    num_res_blocks: 2
    use_dynamic_ops: True
    dynamic_conv_kwargs:
      num_layers: 4
      wv_planes: 256

  decoder:
    _target_: eo_vae.models.Decoder
    z_channels: 32
    resolution: 256
    out_ch: 3
    ch: 128
    ch_mult: [ 1,2,4,4 ]  # num_down = len(ch_mult)-1
    num_res_blocks: 2
    use_dynamic_ops: True
    dynamic_conv_kwargs:
      num_layers: 4
      wv_planes: 256

datamodule:
  _target_: eo_vae.datasets.sen2naip.Sen2NaipLatentCrossSensorDataModule
  root: /mnt/SSD2/nils/datasets/sen2naip/cross-sensor/eo-vae-batch-norm/eo-vae-spatial-norm
  batch_size: 16
  num_workers: 4
  latent_scale_factor: 1.0
  normalize: False # we use batch norm encoded latents
